
import { GoogleGenAI, Chat, GenerateContentResponse, Type, FunctionDeclaration } from '@google/genai';
import type { PromptData, FewShotExample, OptimizationPair } from '../types';
import { canUseTokens, incrementTokenUsage } from './subscriptionService';
import { estimateFullTokens } from '../utils/tokenEstimator';
import { getUserApiKey, updateApiKeyUsage } from './apiKeyService';

// Helper function to get the API key and initialize the AI client
// Tenta usar a API Key do usu√°rio primeiro, depois a do sistema
const getAI = async (): Promise<{ ai: GoogleGenAI; usingUserKey: boolean; apiKey: string }> => {
    console.log('üîë [getAI] Buscando API Key...');
    
    // Primeiro, tenta buscar a API Key do usu√°rio
    let apiKey = await getUserApiKey('gemini');
    let usingUserKey = false;
    
    if (apiKey) {
        usingUserKey = true;
        console.log('‚úÖ [getAI] Usando API Key do usu√°rio (Gemini)');
    } else {
        console.log('üîç [getAI] Nenhuma API Key do usu√°rio, buscando chave do sistema...');
        
        // Se n√£o houver API Key do usu√°rio, usa a do sistema
        // Suporta tanto Next.js quanto Vite
        apiKey = 
          (typeof process !== 'undefined' && process.env?.GEMINI_API_KEY) ||
          (typeof process !== 'undefined' && process.env?.NEXT_PUBLIC_GEMINI_API_KEY) ||
          (typeof process !== 'undefined' && process.env?.API_KEY) ||
          (typeof import.meta !== 'undefined' && (import.meta as any).env?.GEMINI_API_KEY) ||
          (typeof import.meta !== 'undefined' && (import.meta as any).env?.API_KEY) ||
          '';
        
        console.log('üîç [getAI] Verificando vari√°veis de ambiente:', {
            hasGeminiApiKey: !!(typeof process !== 'undefined' && process.env?.GEMINI_API_KEY),
            hasNextPublicGeminiKey: !!(typeof process !== 'undefined' && process.env?.NEXT_PUBLIC_GEMINI_API_KEY),
            hasApiKey: !!(typeof process !== 'undefined' && process.env?.API_KEY),
            foundKey: !!apiKey,
            keyLength: apiKey?.length || 0,
        });
        
        if (!apiKey) {
            console.error('‚ùå [getAI] GEMINI_API_KEY n√£o configurada!');
            console.error('‚ùå [getAI] Configure na Vercel: Settings ‚Üí Environment Variables ‚Üí GEMINI_API_KEY');
            throw new Error("API_KEY n√£o configurada. Configure sua pr√≥pria API Key nas Configura√ß√µes ou configure a GEMINI_API_KEY do sistema na Vercel.");
        }
        console.log('‚úÖ [getAI] Usando API Key do sistema (Gemini) - comprimento:', apiKey.length);
    }
    
    return {
        ai: new GoogleGenAI({ apiKey }),
        usingUserKey,
        apiKey
    };
};

const model = 'gemini-2.5-flash';

export const createFinalPrompt = async (data: PromptData): Promise<string> => {
    // Validar campos obrigat√≥rios
    if (!data.persona || !data.persona.trim()) {
        throw new Error('Campo "Persona" √© obrigat√≥rio');
    }
    if (!data.objetivo || !data.objetivo.trim()) {
        throw new Error('Campo "Objetivo" √© obrigat√≥rio');
    }
    if (!data.contextoNegocio || !data.contextoNegocio.trim()) {
        throw new Error('Campo "Contexto do Neg√≥cio" √© obrigat√≥rio');
    }
    if (!data.contexto || !data.contexto.trim()) {
        throw new Error('Campo "Contexto da Intera√ß√£o" √© obrigat√≥rio');
    }

    const { ai, usingUserKey } = await getAI();
    let basePromptInfo = `
# INFORMA√á√ïES BASE PARA GERA√á√ÉO DO PROMPT MESTRE

## IDENTIDADE CENTRAL & EXPERTISE (PERSONA)
${data.persona.trim()}

## OBJETIVO PRINCIPAL
${data.objetivo.trim()}

## CONTEXTO DO NEG√ìCIO
${data.contextoNegocio.trim()}

## CONTEXTO DA INTERA√á√ÉO
${data.contexto.trim()}
`;
    if (data.ferramentas.length > 0) {
        basePromptInfo += `\n## FERRAMENTAS DISPON√çVEIS (TOOLS)\n`;
        data.ferramentas.forEach(f => {
            basePromptInfo += `- **${f.nome}**: ${f.descricao}\n`;
        });
    }

    if (data.variaveisDinamicas.length > 0) {
        basePromptInfo += `\n## VARI√ÅVEIS DIN√ÇMICAS\n`;
        data.variaveisDinamicas.forEach(v => {
            basePromptInfo += `- **{{${v.chave}}}**: (Valor de exemplo: ${v.valor})\n`;
        });
    }
    
    basePromptInfo += `
## REGRAS CR√çTICAS INVIOL√ÅVEIS
${data.regras.map(regra => `- ${regra}`).join('\n')}
`;

    if (data.exemplos.length > 0) {
        basePromptInfo += `\n## EXEMPLOS (FEW-SHOT LEARNING)\n`;
        data.exemplos.forEach(ex => {
            basePromptInfo += `### Exemplo:\n- **Usu√°rio:** ${ex.user}\n- **Agente:** ${ex.agent}\n`;
        });
    }

    if (data.fluxos && data.fluxos.length > 0) {
         basePromptInfo += `\n## FLUXOS DE INTERA√á√ÉO ESPEC√çFICOS\n`;
         data.fluxos.forEach(fluxo => {
             basePromptInfo += `### Fluxo: ${fluxo.nome} (${fluxo.tipoPrompt})\n- Objetivo: ${fluxo.objetivo}\n`;
             if (fluxo.baseConhecimentoRAG) basePromptInfo += `- Contexto/RAG: ${fluxo.baseConhecimentoRAG}\n`;
             if (fluxo.reforcarCoT) basePromptInfo += `- [REFOR√áAR CHAIN-OF-THOUGHT NESTE FLUXO]\n`;
             if (fluxo.ativarGuardrails) basePromptInfo += `- [ATIVAR GUARDRAILS ESTRITOS NESTE FLUXO]\n`;
             if (fluxo.fewShotExamples) basePromptInfo += `- Exemplos do fluxo:\n${fluxo.fewShotExamples}\n`;
         });
    }

    // INSTRU√á√ïES PARA O AGENTE FINAL (BASEADO NO `formatoSaida`)
    basePromptInfo += `
## FORMATO E ESTRUTURA DE RESPOSTA DO AGENTE
- **Formato Alvo do Agente:** ${data.formatoSaida.toUpperCase()}
- **Estrutura Esperada:** ${data.estruturaSaida}
`;

    if (['json', 'xml', 'yaml'].includes(data.formatoSaida)) {
      basePromptInfo += `
### RESTRI√á√ïES ESTRITAS DE FORMATO DO AGENTE (${data.formatoSaida.toUpperCase()})
Para garantir a integridade t√©cnica da resposta, as seguintes restri√ß√µes S√ÉO OBRIGAT√ìRIAS para o Agente Final:
1. **SEM MARKDOWN NA RESPOSTA FINAL:** A resposta do agente N√ÉO DEVE conter blocos de c√≥digo Markdown. Deve ser apenas o dado puro.
2. **SEM TEXTO CONVERSACIONAL:** A resposta deve come√ßar imediatamente com o primeiro caractere v√°lido do formato.
`;
    } else if (data.formatoSaida === 'text') {
        basePromptInfo += `
### RESTRI√á√ïES DE FORMATO DO AGENTE (TEXTO PURO)
1. **LINGUAGEM NATURAL:** A resposta deve ser em texto corrido natural, focado no usu√°rio final.
2. **SEM FORMATA√á√ÉO COMPLEXA:** Evite uso excessivo de Markdown. NUNCA use blocos de c√≥digo para texto normal.
`;
    }

    // INSTRU√á√ïES PARA O GERADOR DO PROMPT MESTRE (BASEADO NO `masterPromptFormat`)
    let expansionPrompt = `
Voc√™ √© um especialista s√™nior em engenharia de prompts. Sua tarefa √© pegar as informa√ß√µes base fornecidas e expandi-las em um "PROMPT MESTRE" detalhado e robusto.

**INFORMA√á√ïES BASE:**
---
${basePromptInfo.trim()}
---

**REQUISITOS DO PROMPT MESTRE:**
1. **EXPANS√ÉO INTELIGENTE:** Use as informa√ß√µes base como n√∫cleo. Expanda se√ß√µes, adicione detalhes, explica√ß√µes e exemplos consistentes com a persona.
2. **TAMANHO ALVO:** Aproximadamente **${data.promptSize}** caracteres.
3. **FORMATO DE SA√çDA DO PROMPT MESTRE:** O prompt mestre que VOC√ä vai gerar deve estar no formato **${data.masterPromptFormat.toUpperCase()}**.
`;

    if (data.masterPromptFormat === 'markdown') {
        expansionPrompt += `
**ESTRUTURA MARKDOWN ESPERADA (CR√çTICO - DEVE SER MARKDOWN 100% COM HIERARQUIA):**

O prompt mestre DEVE seguir uma hierarquia Markdown completa e bem estruturada:

1. **T√çTULOS COM HIERARQUIA:**
   - Use # (H1) apenas para o t√≠tulo principal do prompt
   - Use ## (H2) para se√ß√µes principais (PERSONA, OBJETIVO, CONTEXTO, REGRAS, etc.)
   - Use ### (H3) para subse√ß√µes dentro de cada se√ß√£o principal
   - Use #### (H4) para sub-subse√ß√µes quando necess√°rio
   - Use ##### (H5) para detalhamentos finos quando necess√°rio

2. **FORMATA√á√ÉO:**
   - Use **negrito** para destacar conceitos importantes
   - Use *it√°lico* para √™nfase
   - Use c√≥digo inline (backtick) para nomes de vari√°veis, fun√ß√µes ou termos t√©cnicos
   - Use listas ordenadas (1., 2., 3.) para instru√ß√µes sequenciais
   - Use listas n√£o ordenadas (- ou *) para itens relacionados
   - Use > para cita√ß√µes ou blocos de destaque quando apropriado
   - Use blocos de c√≥digo (tr√™s backticks) quando necess√°rio

3. **ESTRUTURA ESPERADA:**
   - T√≠tulo principal com #
   - Se√ß√µes principais com ##
   - Subse√ß√µes com ###
   - Conte√∫do formatado com listas, negrito, it√°lico e c√≥digo inline
   - Organiza√ß√£o hier√°rquica clara para facilitar leitura por LLMs

4. **EXEMPLO DE ESTRUTURA:**
(BLOCO DE C√ìDIGO MARKDOWN)
# T√çTULO PRINCIPAL DO PROMPT

## PERSONA

### Identidade Central
[conte√∫do detalhado]

### Especializa√ß√£o
[conte√∫do detalhado]

## OBJETIVO

### Objetivo Principal
[conte√∫do detalhado]

## REGRAS

### Regras Cr√≠ticas
- Regra 1: [descri√ß√£o]
- Regra 2: [descri√ß√£o]
(FIM DO BLOCO)

Sua resposta deve ser APENAS o texto Markdown do prompt final, SEM explica√ß√µes ou coment√°rios adicionais.
`;
    } else if (data.masterPromptFormat === 'json') {
        expansionPrompt += `
**ESTRUTURA JSON ESPERADA (CR√çTICO - DEVE SER JSON 100% ESTRUTURADO):**

O prompt mestre DEVE ser um objeto JSON v√°lido, bem formatado e estruturado:

1. **FORMATA√á√ÉO OBRIGAT√ìRIA:**
   - Use indenta√ß√£o de 2 espa√ßos para cada n√≠vel
   - Use quebras de linha ap√≥s cada chave/valor
   - Use v√≠rgulas apropriadas (n√£o v√≠rgula final)
   - Use aspas duplas para todas as strings
   - Use arrays para listas de itens
   - Use objetos aninhados para estruturas hier√°rquicas

2. **ESTRUTURA SUGERIDA:**
   {
     "persona": {
       "identity": "...",
       "expertise": "...",
       "tone": "..."
     },
     "objective": {
       "primary": "...",
       "secondary": ["...", "..."]
     },
     "context": {
       "business": "...",
       "interaction": "..."
     },
     "rules": [
       "Regra 1: ...",
       "Regra 2: ..."
     ],
     "instructions": {
       "format": "...",
       "style": "...",
       "examples": ["...", "..."]
     }
   }

3. **REQUISITOS CR√çTICOS:**
   - O JSON DEVE ser v√°lido e bem formatado (passar em JSON.parse())
   - Use indenta√ß√£o consistente (2 espa√ßos por n√≠vel)
   - Strings podem conter quebras de linha \\n quando necess√°rio
   - Strings podem conter markdown DENTRO delas se apropriado
   - Estruture de forma hier√°rquica para facilitar leitura por LLMs

4. **N√ÉO FA√áA:**
   - N√£o retorne JSON em um bloco de c√≥digo markdown (tr√™s backticks json)
   - N√£o adicione explica√ß√µes antes ou depois do JSON
   - N√£o use formata√ß√£o compacta (tudo em uma linha)
   - N√£o use aspas simples para strings

Sua resposta deve ser APENAS o objeto JSON v√°lido, SEM blocos de c√≥digo markdown, SEM explica√ß√µes, APENAS o JSON puro e bem formatado.
`;
    }

    // Verificar limite de tokens antes de fazer a chamada
    const estimatedTokens = estimateFullTokens(expansionPrompt, '');
    const tokenCheck = await canUseTokens(estimatedTokens);
    
    if (!tokenCheck.allowed) {
        throw new Error(tokenCheck.reason || 'Limite de tokens excedido');
    }

    const response = await ai.models.generateContent({
        model: 'gemini-2.5-pro',
        contents: expansionPrompt,
        config: data.masterPromptFormat === 'json' ? { responseMimeType: "application/json" } : undefined
    });
    
    // Verificar se response.text existe
    if (!response.text) {
        throw new Error('Resposta vazia do modelo Gemini');
    }
    
    // Incrementar uso de tokens ap√≥s a chamada
    const actualTokens = estimateFullTokens(expansionPrompt, response.text);
    await incrementTokenUsage(actualTokens);
    
    // Se estiver usando API Key do usu√°rio, atualizar estat√≠sticas
    if (usingUserKey) {
        await updateApiKeyUsage('gemini', actualTokens);
    }
    
    let finalText = response.text.trim();
    
    // Se for JSON, garantir que est√° bem formatado
    if (data.masterPromptFormat === 'json') {
        try {
            // Remover blocos de c√≥digo markdown se houver
            finalText = finalText.replace(/^```json\s*/i, '').replace(/\s*```$/i, '').trim();
            finalText = finalText.replace(/^```\s*/i, '').replace(/\s*```$/i, '').trim();
            
            // Fazer parse para validar e reformatar
            const parsed = JSON.parse(finalText);
            // Reformatar com indenta√ß√£o de 2 espa√ßos
            finalText = JSON.stringify(parsed, null, 2);
        } catch (e) {
            console.warn('‚ö†Ô∏è Erro ao formatar JSON, retornando texto original:', e);
            // Se falhar o parse, tentar extrair JSON do texto
            const jsonMatch = finalText.match(/\{[\s\S]*\}/);
            if (jsonMatch) {
                try {
                    const parsed = JSON.parse(jsonMatch[0]);
                    finalText = JSON.stringify(parsed, null, 2);
                } catch (e2) {
                    console.error('‚ùå Erro ao extrair JSON:', e2);
                }
            }
        }
    }
    
    return finalText;
};

let chatInstance: Chat | null = null;
let currentApiKeyInfo: { usingUserKey: boolean; apiKey: string } | null = null;

export const startChat = async (systemInstruction: string): Promise<void> => {
    const { ai, usingUserKey, apiKey } = await getAI();
    currentApiKeyInfo = { usingUserKey, apiKey };
    // Se o prompt mestre for JSON, tentamos extrair algo us√°vel como instru√ß√£o de sistema se poss√≠vel,
    // ou usamos o JSON inteiro como string.
    let finalInstruction = systemInstruction;
    try {
        // Tenta parsear se parece JSON para talvez extrair campos espec√≠ficos se necess√°rio no futuro.
        // Por enquanto, passar o JSON stringificado como system prompt tamb√©m funciona para muitos modelos.
        JSON.parse(systemInstruction);
    } catch (e) {
        // N√£o √© JSON, continua como texto normal
    }

    chatInstance = ai.chats.create({
        model: model,
        config: {
            systemInstruction: finalInstruction
        }
    });
};

export const continueChat = async (message: string, promptContent?: string): Promise<string> => {
    if (!chatInstance) {
        throw new Error("Chat n√£o iniciado. Selecione uma vers√£o de prompt para come√ßar.");
    }
    
    try {
        // Verificar limite de tokens antes de fazer a chamada
        const estimatedTokens = estimateFullTokens(message + (promptContent || ''), '');
        const tokenCheck = await canUseTokens(estimatedTokens);
        
        if (!tokenCheck.allowed) {
            throw new Error(tokenCheck.reason || 'Limite de tokens excedido');
        }

        const response: GenerateContentResponse = await chatInstance.sendMessage({ message });
        
        // Verificar se response.text existe
        if (!response.text) {
            throw new Error('Resposta vazia do modelo Gemini');
        }
        
        // Incrementar uso de tokens ap√≥s a chamada
        const actualTokens = estimateFullTokens(message, response.text);
        await incrementTokenUsage(actualTokens);
        
        // Se estiver usando API Key do usu√°rio, atualizar estat√≠sticas
        if (currentApiKeyInfo?.usingUserKey) {
            await updateApiKeyUsage('gemini', actualTokens);
        }
        
        return response.text;
    } catch (error: any) {
        console.error("Error in chat:", error);
        // Se o erro j√° √© uma mensagem de limite, re-lan√ßar
        if (error.message && error.message.includes('Limite de tokens')) {
            throw error;
        }
        throw new Error(error.message || "Falha ao se comunicar com a API da Gemini no chat.");
    }
};

export const generateExamples = async (data: PromptData): Promise<Omit<FewShotExample, 'id'>[]> => {
    const { ai, usingUserKey, apiKey } = await getAI();
    try {
        const generationContext = `
        **Persona do Agente:** ${data.persona}
        **Objetivo Principal:** ${data.objetivo}
        **Contexto do Neg√≥cio:** ${data.contextoNegocio}
        **Contexto da Intera√ß√£o:** ${data.contexto}
        **Regras:** ${data.regras.join(', ')}
        **Formato de Sa√≠da do Agente:** ${data.formatoSaida.toUpperCase()}
        `;

        let generationPrompt = `
        Com base no contexto, gere 2-3 exemplos de intera√ß√µes (usu√°rio/agente).
        `;

        if (['json', 'xml', 'yaml'].includes(data.formatoSaida)) {
             generationPrompt += ` IMPORTANTE: A resposta do 'agent' nos exemplos deve ser EXATAMENTE no formato ${data.formatoSaida.toUpperCase()} solicitado.`;
        }
        
        generationPrompt += `
        **Contexto:**
        ---
        ${generationContext}
        ---
        Retorne os exemplos como um array JSON.
        `;
        
        const response = await ai.models.generateContent({
            model: model,
            contents: generationPrompt,
            config: {
                responseMimeType: "application/json",
                responseSchema: {
                    type: Type.ARRAY,
                    items: {
                        type: Type.OBJECT,
                        properties: {
                            user: { type: Type.STRING },
                            agent: { type: Type.STRING }
                        },
                        required: ['user', 'agent']
                    }
                }
            }
        });

        if (!response.text) {
            throw new Error('Resposta vazia do modelo Gemini ao gerar exemplos');
        }

        return JSON.parse(response.text.trim()) as Omit<FewShotExample, 'id'>[];
    } catch (error) {
        console.error("Error generating examples:", error);
        throw new Error("Falha ao gerar exemplos.");
    }
};

export const optimizePrompt = async (currentPrompt: string, corrections: OptimizationPair[], instructions: string = ''): Promise<string> => {
    const { ai, usingUserKey, apiKey } = await getAI();
    try {
        const correctionsSection = corrections.length > 0 ? corrections.map((c, i) => `
### Corre√ß√£o ${i + 1}
- **Consulta:** "${c.userQuery}"
- **Resposta Antiga (Ruim):** "${c.originalResponse}"
- **Resposta Nova (Ideal):** "${c.correctedResponse}"
`).join('\n') : 'Nenhuma corre√ß√£o espec√≠fica de chat.';

        const optimizationPrompt = `
Voc√™ √© um especialista em engenharia de prompts. Refatore o prompt abaixo com base no feedback.
MANTENHA O MESMO FORMATO (Markdown ou JSON) do prompt original.

**PROMPT ATUAL:**
---
${currentPrompt}
---

**FEEDBACK (CORRE√á√ïES):**
---
${correctionsSection}
---

**INSTRU√á√ïES MANUAIS:**
---
${instructions.trim() || 'Nenhuma instru√ß√£o adicional.'}
---

Reescreva o prompt para corrigir os problemas identificados. Retorne APENAS o novo prompt.
`;

        // Tenta detectar se o prompt atual √© JSON para for√ßar a sa√≠da JSON na otimiza√ß√£o tamb√©m
        let isJson = false;
        try {
            JSON.parse(currentPrompt);
            isJson = true;
        } catch (e) {}

        const optimizationPromptWithFormatting = isJson ? `${optimizationPrompt}

**IMPORTANTE - FORMATO JSON:**
- O prompt otimizado DEVE ser um JSON v√°lido e bem formatado
- Use indenta√ß√£o de 2 espa√ßos por n√≠vel
- Use quebras de linha ap√≥s cada chave/valor
- N√ÉO retorne JSON em bloco de c√≥digo markdown (sem tr√™s backticks json)
- Retorne APENAS o objeto JSON puro, bem formatado e estruturado
- Garanta que o JSON seja v√°lido e pass√≠vel de parse com JSON.parse()
` : optimizationPrompt;

        const response = await ai.models.generateContent({
            model: 'gemini-2.5-pro',
            contents: optimizationPromptWithFormatting,
            config: isJson ? { responseMimeType: "application/json" } : undefined
        });

        if (!response.text) {
            throw new Error('Resposta vazia do modelo Gemini ao otimizar prompt');
        }

        let optimizedText = response.text.trim();

        // Se for JSON, formatar e limpar
        if (isJson) {
            try {
                // Remover blocos de c√≥digo markdown se houver
                optimizedText = optimizedText.replace(/^```json\s*/i, '').replace(/\s*```$/i, '').trim();
                optimizedText = optimizedText.replace(/^```\s*/i, '').replace(/\s*```$/i, '').trim();
                
                // Parsear e reformatar com indenta√ß√£o de 2 espa√ßos
                const parsed = JSON.parse(optimizedText);
                optimizedText = JSON.stringify(parsed, null, 2);
            } catch (parseError) {
                console.warn('‚ö†Ô∏è Erro ao formatar JSON otimizado, tentando extrair JSON:', parseError);
                // Tentar extrair JSON do texto se houver
                const jsonMatch = optimizedText.match(/\{[\s\S]*\}/);
                if (jsonMatch) {
                    try {
                        const parsed = JSON.parse(jsonMatch[0]);
                        optimizedText = JSON.stringify(parsed, null, 2);
                    } catch (e2) {
                        console.error('‚ùå Erro ao extrair e formatar JSON:', e2);
                        // Se falhar, retornar o texto original
                    }
                }
            }
        }

        return optimizedText;
    } catch (error: any) {
        console.error("Error optimizing prompt:", error);
        // Garantir que o erro seja uma string ou objeto com mensagem
        const errorMessage = error?.message || error?.toString() || "Falha na otimiza√ß√£o.";
        throw new Error(errorMessage);
    }
};

export const explainPrompt = async (promptContent: string): Promise<string> => {
    const { ai, usingUserKey, apiKey } = await getAI();
    const explanationRequest = `
Voc√™ √© um especialista em engenharia de prompts e comunica√ß√£o t√©cnica. Sua tarefa √© analisar o prompt de IA fornecido e gerar uma documenta√ß√£o clara, detalhada e pedag√≥gica sobre ele. O p√∫blico-alvo desta documenta√ß√£o s√£o clientes e membros n√£o-t√©cnicos da equipe do projeto.

A documenta√ß√£o deve explicar:
1. **Objetivo Geral:** Qual √© a principal fun√ß√£o do agente de IA que usar√° este prompt?
2. **Persona e Tom de Voz:** Como o agente se comportar√°? Qual √© sua personalidade?
3. **Principais Regras e Limita√ß√µes:** Quais s√£o as diretrizes mais importantes que o agente deve seguir?
4. **Entradas e Sa√≠das:** Que tipo de informa√ß√£o o agente espera e como ele deve formatar suas respostas?
5. **Exemplos Pr√°ticos:** Se houver exemplos, explique o que eles demonstram.
6. **Fluxo de Conversa:** Descreva um exemplo de como uma conversa com este agente poderia acontecer.

Use formata√ß√£o Markdown (t√≠tulos, listas, negrito) para tornar o documento f√°cil de ler e bem estruturado. A linguagem deve ser simples e evitar jarg√µes t√©cnicos sempre que poss√≠vel.

**PROMPT PARA ANALISAR:**
---
${promptContent}
---

Retorne APENAS a documenta√ß√£o em Markdown.`;

    try {
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-pro',
            contents: explanationRequest
        });
        
        if (!response.text) {
            throw new Error('Resposta vazia do modelo Gemini ao explicar prompt');
        }
        
        return response.text;
    } catch (error) {
        console.error("Error explaining prompt:", error);
        throw new Error("Falha ao gerar a explica√ß√£o do prompt.");
    }
};


// --- Document Analysis & Audio Assistant Services remain largely the same ---
// (Omitting them here for brevity as they didn't need changes for this specific request, 
// but they would be included in the full file content in a real scenario if I wasn't using the XML format efficiently)
// RE-INCLUDING FULL CONTENT TO BE SAFE as requested by the prompt format.

/**
 * Fun√ß√£o auxiliar para retry com backoff exponencial
 */
const retryWithBackoff = async <T>(
    fn: () => Promise<T>,
    maxRetries: number = 3,
    initialDelay: number = 1000
): Promise<T> => {
    let lastError: any;
    
    for (let attempt = 0; attempt <= maxRetries; attempt++) {
        try {
            return await fn();
        } catch (error: any) {
            lastError = error;
            
            // Verificar se √© um erro que vale a pena tentar novamente
            const isRetryable = 
                error?.status === 503 || // Service Unavailable
                error?.status === 429 || // Too Many Requests
                error?.status === 500 || // Internal Server Error
                error?.status === 502 || // Bad Gateway
                error?.code === 503 ||
                error?.code === 429 ||
                error?.code === 500 ||
                error?.code === 502 ||
                error?.message?.includes('overloaded') ||
                error?.message?.includes('try again later') ||
                error?.message?.includes('rate limit') ||
                error?.message?.includes('UNAVAILABLE');
            
            if (!isRetryable || attempt === maxRetries) {
                throw error;
            }
            
            // Calcular delay com backoff exponencial
            const delay = initialDelay * Math.pow(2, attempt);
            console.log(`‚ö†Ô∏è Tentativa ${attempt + 1}/${maxRetries + 1} falhou. Tentando novamente em ${delay}ms...`);
            await new Promise(resolve => setTimeout(resolve, delay));
        }
    }
    
    throw lastError;
};

export const analyzeDocument = async (fileBase64: string, mimeType: string, fileName?: string): Promise<Partial<PromptData>> => {
    const { ai, usingUserKey, apiKey } = await getAI();

    // Para arquivos CSV, melhorar o prompt de an√°lise
    const isCsv = mimeType === 'text/csv' || fileName?.toLowerCase().endsWith('.csv');
    
    const docPart = {
        inlineData: {
            data: fileBase64,
            mimeType: mimeType
        }
    };

    const extractionPrompt = isCsv 
        ? `
Analise este arquivo CSV e extraia informa√ß√µes relevantes para criar um prompt de IA.
Identifique padr√µes, estruturas de dados, contexto de neg√≥cio e regras de processamento.

Para arquivos CSV, foque em:
- Entender a estrutura e prop√≥sito dos dados
- Identificar campos importantes e suas rela√ß√µes
- Extrair contexto de neg√≥cio dos cabe√ßalhos e dados
- Identificar regras de valida√ß√£o ou processamento impl√≠citas

Campos JSON esperados: persona, objetivo, contextoNegocio, contexto, regras (array de strings).
Retorne sempre um JSON v√°lido, mesmo que alguns campos estejam vazios.
`
        : `
Analise o documento e extraia informa√ß√µes para um prompt de IA.
${fileName ? `Nome do arquivo: ${fileName}\n` : ''}
Campos JSON esperados: persona, objetivo, contextoNegocio, contexto, regras (array de strings).
Retorne sempre um JSON v√°lido, mesmo que alguns campos estejam vazios.
`;

    try {
        const response = await retryWithBackoff(async () => {
            // Para CSV, usar uma abordagem mais tolerante com o schema
            const schema = isCsv
                ? {
                    type: Type.OBJECT,
                    properties: {
                        persona: { type: Type.STRING },
                        objetivo: { type: Type.STRING },
                        contextoNegocio: { type: Type.STRING },
                        contexto: { type: Type.STRING },
                        regras: { type: Type.ARRAY, items: { type: Type.STRING } }
                    },
                    // Campos n√£o obrigat√≥rios para CSV, permitindo an√°lise parcial
                    required: []
                }
                : {
                    type: Type.OBJECT,
                    properties: {
                        persona: { type: Type.STRING },
                        objetivo: { type: Type.STRING },
                        contextoNegocio: { type: Type.STRING },
                        contexto: { type: Type.STRING },
                        regras: { type: Type.ARRAY, items: { type: Type.STRING } }
                    },
                    required: ['persona', 'objetivo', 'contextoNegocio', 'contexto', 'regras']
                };

            // Estimar tokens para o documento (aproxima√ß√£o)
            const estimatedDocTokens = estimateFullTokens(extractionPrompt, '');
            const tokenCheck = await canUseTokens(estimatedDocTokens);
            
            if (!tokenCheck.allowed) {
                throw new Error(tokenCheck.reason || 'Limite de tokens excedido');
            }

            const response = await ai.models.generateContent({
                model: 'gemini-2.5-pro',
                contents: { parts: [docPart, { text: extractionPrompt }] },
                config: {
                    responseMimeType: "application/json",
                    responseSchema: schema
                }
            });
            
            // Verificar se response.text existe
            if (!response.text) {
                throw new Error('Resposta vazia do modelo Gemini ao extrair dados');
            }
            
            // Incrementar uso de tokens ap√≥s a chamada
            const actualTokens = estimateFullTokens(extractionPrompt, response.text);
            await incrementTokenUsage(actualTokens);
            
            // Se estiver usando API Key do usu√°rio, atualizar estat√≠sticas
            if (usingUserKey) {
                await updateApiKeyUsage('gemini', actualTokens);
            }
            
            return response;
        }, 3, 500); // 3 tentativas, come√ßando com 500ms (reduzido de 2s para acelerar)
        
        // Verificar se a resposta tem texto
        if (!response || !response.text) {
            console.error("Resposta vazia ou inv√°lida da API:", response);
            throw new Error("A API retornou uma resposta vazia. Tente novamente.");
        }
        
        const responseText = response.text.trim();
        
        if (!responseText || responseText === 'undefined' || responseText === 'null') {
            console.error("Texto da resposta est√° vazio ou inv√°lido:", responseText);
            throw new Error("A API retornou dados inv√°lidos. Tente novamente.");
        }
        
        // Tentar fazer parse do JSON
        try {
            const parsed = JSON.parse(responseText);
            
            // Garantir que todos os campos esperados existam (mesmo que vazios)
            const result: Partial<PromptData> = {
                persona: parsed.persona || '',
                objetivo: parsed.objetivo || '',
                contextoNegocio: parsed.contextoNegocio || '',
                contexto: parsed.contexto || '',
                regras: Array.isArray(parsed.regras) ? parsed.regras : []
            };
            
            return result;
        } catch (parseError: any) {
            console.error("Erro ao fazer parse do JSON:", parseError);
            console.error("Texto recebido:", responseText.substring(0, 500));
            
            // Tentar extrair JSON de uma string que pode estar envolvida em markdown ou outros caracteres
            try {
                const jsonMatch = responseText.match(/\{[\s\S]*\}/);
                if (jsonMatch) {
                    const parsed = JSON.parse(jsonMatch[0]);
                    return {
                        persona: parsed.persona || '',
                        objetivo: parsed.objetivo || '',
                        contextoNegocio: parsed.contextoNegocio || '',
                        contexto: parsed.contexto || '',
                        regras: Array.isArray(parsed.regras) ? parsed.regras : []
                    };
                }
            } catch (secondTryError) {
                console.error("Segunda tentativa de parse tamb√©m falhou:", secondTryError);
            }
            
            throw new Error(`Erro ao processar a resposta da API${fileName ? ` para ${fileName}` : ''}. O formato retornado √© inv√°lido. Tente novamente.`);
        }
    } catch (error: any) {
        console.error("Error analyzing document:", error);
        
        // Se j√° √© um erro formatado, apenas propagar
        if (error?.message && !error?.status && !error?.code) {
            throw error;
        }
        
        // Mensagens de erro mais espec√≠ficas
        if (error?.status === 503 || error?.code === 503 || error?.message?.includes('overloaded') || error?.message?.includes('UNAVAILABLE')) {
            throw new Error("O servi√ßo est√° temporariamente sobrecarregado. Por favor, tente novamente em alguns instantes.");
        } else if (error?.status === 429 || error?.code === 429 || error?.message?.includes('rate limit')) {
            throw new Error("Muitas requisi√ß√µes. Por favor, aguarde alguns segundos antes de tentar novamente.");
        } else if (error?.status === 400 || error?.code === 400 || error?.message?.includes('400')) {
            throw new Error("Formato de arquivo n√£o suportado ou inv√°lido. Tente converter para PDF ou TXT.");
        } else if (error?.status === 401 || error?.code === 401) {
            throw new Error("Erro de autentica√ß√£o. Verifique sua chave de API do Gemini.");
        } else if (error?.status === 413 || error?.code === 413) {
            throw new Error("Arquivo muito grande. Tente um arquivo menor ou divida o documento.");
        } else if (error?.message?.includes('JSON') || error?.message?.includes('parse')) {
            throw new Error("Erro ao processar a resposta da API. Tente novamente.");
        } else {
            throw new Error(error?.message || "Falha ao analisar o documento. Tente novamente mais tarde.");
        }
    }
};

const formUpdateTools: FunctionDeclaration[] = [
    { name: 'updatePersona', parameters: { type: Type.OBJECT, properties: { text: { type: Type.STRING } }, required: ['text'] } },
    { name: 'updateObjetivo', parameters: { type: Type.OBJECT, properties: { text: { type: Type.STRING } }, required: ['text'] } },
    { name: 'updateContextoNegocio', parameters: { type: Type.OBJECT, properties: { text: { type: Type.STRING } }, required: ['text'] } },
    { name: 'updateContextoInteracao', parameters: { type: Type.OBJECT, properties: { text: { type: Type.STRING } }, required: ['text'] } },
    // FIX: Corrected the type from a string literal 'string' to the enum Type.STRING for type safety and correctness.
    { name: 'addRegra', parameters: { type: Type.OBJECT, properties: { text: { type: Type.STRING } }, required: ['text'] } },
    { name: 'addExemplo', parameters: { type: Type.OBJECT, properties: { user: { type: Type.STRING }, agent: { type: Type.STRING } }, required: ['user', 'agent'] } }
];

const assistantSystemInstruction = `Voc√™ √© um assistente de preenchimento de formul√°rio por voz. Transcreva o √°udio do usu√°rio e use as ferramentas para atualizar os campos. Responda com [TRANSCRI√á√ÉO: ...] seguido de uma confirma√ß√£o curta.`;

export const processAudioCommand = async (audioBase64: string, audioMimeType: string): Promise<GenerateContentResponse> => {
    const { ai, usingUserKey, apiKey } = await getAI();
    try {
        return await ai.models.generateContent({
            model: 'gemini-2.5-pro',
            contents: { parts: [{ inlineData: { mimeType: audioMimeType, data: audioBase64 } }, { text: "Processe este comando." }] },
            config: {
                systemInstruction: assistantSystemInstruction,
                tools: [{ functionDeclarations: formUpdateTools }]
            }
        });
    } catch (error) {
        console.error("Error processing audio:", error);
        throw new Error("Falha ao processar √°udio.");
    }
};